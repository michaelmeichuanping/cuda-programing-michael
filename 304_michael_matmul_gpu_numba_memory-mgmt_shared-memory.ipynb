{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6a1ed4-e343-4764-876e-b44ccc579b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "import numpy as np\n",
    "import math\n",
    "from time import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4deb767b-ec36-4b0f-80e9-879a6124d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variable for block size\n",
    "# thread per block = BLOCK_SIZE x BLOCK_SIZE \n",
    "# It will determines: 1) CUDA execution configuration 2) size of shared memory in every SM\n",
    "BLOCK_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade2bbbc-fe86-4b08-a2ce-4d59038d5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel function of matmul C = A * B without shared memory (for comparison)\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    #  Here can also use “row, col = cuda.grid(2)” \n",
    "    row = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    col = cuda.threadIdx.y + cuda.blockDim.y * cuda.blockIdx.y\n",
    "    \n",
    "    if row < C.shape[0] and col < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[row, k] * B[k, col]\n",
    "        C[row, col] = tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18746578-b41c-41d3-8a20-5ed62a44be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel function of matmul withshared memory \n",
    "@cuda.jit\n",
    "def matmul_shared_memory(A, B, C):\n",
    "    # Create shared memoy buffer for 2 matrixies in every SM by using, in same size as the CUDA block \n",
    "    # Note: we will see these 2 buffers in every SM’s shared memory\n",
    "    # The shared-memory matrixes are defined at kernel function level, \n",
    "    # but they can be accessed by all the threads in the current SM\n",
    "    sA = cuda.shared.array(shape=(BLOCK_SIZE, BLOCK_SIZE), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(BLOCK_SIZE, BLOCK_SIZE), dtype=float32)\n",
    "\n",
    "    # get the current’s thread’ index in the current block \n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    # get the current’s thread’ index in the grid (we can also use “row, col = cuda.grid(2)” here)\n",
    "    row = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    col = cuda.threadIdx.y + cuda.blockDim.y * cuda.blockIdx.y\n",
    "    \n",
    "    # 进行简单越界判断\n",
    "    # 根据矩阵乘法，C的大小是A的行数(shape[0])、B的列数(shape[1])\n",
    "    # 当(row, col)越界时退出\n",
    "    if row >= C.shape[0] or col >= C.shape[1]:\n",
    "        return\n",
    "\n",
    "    # 计算按照当前tA、tB的大小, 需要拆分成多少个子block\n",
    "    exec_num = int(math.ceil(1.0 * A.shape[1] / BLOCK_SIZE))\n",
    "\n",
    "    tmp = 0.\n",
    "\n",
    "\n",
    "    # 对于结果matrix C中的每一个thread，按照”蓝>橙>”顺序，逐个处理A和B中的子模块\n",
    "    # 下面的注释以第一轮循环处理的蓝色block为例，解释内循环的处理流程\n",
    "    for m in range(exec_num):\n",
    "        # 每个thread根据其在目标C里的位置，将A和B蓝色block里对应位置上的那个数据， \n",
    "        # copy到shared memory里 sA和sB的对应位置上\n",
    "        # 第一轮循环后，两个蓝色block里的数据会被对应copy到黄色clock所在SM的sA和sB里\n",
    "        # 第二轮循环后，两个橙色block里的数据会同样被copy该SM的sA和sB里\n",
    "        # 覆盖之前蓝色block的数据\n",
    "        # 重复以上步骤，直至完成\n",
    "        sA[tx, ty] = A[row, ty + m * BLOCK_SIZE]\n",
    "        sB[tx, ty] = B[tx + m * BLOCK_SIZE, col]\n",
    "        # 线程同步，等待Block中所有Thread预加载结束才执行下一步\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # 在每一轮循环里，都需要完成两个同色block的矩阵乘法，并累加到tmp里\n",
    "        # 第一轮循环，用两个蓝色block里的数据求thread点的向量积，累加到tmp里\n",
    "        # 第二轮循环，用两个橙色block里的数据求thread点的向量积，累加到tmp里\n",
    "        # 循环完成后，temp中就保留了A x B = C在该当前thread点的值\n",
    "        for n in range(BLOCK_SIZE):\n",
    "            tmp += sA[tx, n] * sB[n, ty]\n",
    "\n",
    "        # 线程同步，等待Block中所有Thread计算结束\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    #循环完成后，temp中就保留了A x B = C在该当前thread点的值\n",
    "    C[row, col] = tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d4c603-484c-4ed5-a4b4-2675d49f439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul time :4.7024455070495605\n",
      "matmul with shared memory time :2.4234275817871094\n",
      "matmul with shared memory, result correct\n"
     ]
    }
   ],
   "source": [
    "# 初始化矩阵\n",
    "M = 6000\n",
    "N = 4800\n",
    "P = 4000\n",
    "A = np.random.random((M, N)) # 随机生成的 [M x N] 矩阵\n",
    "B = np.random.random((N, P)) # 随机生成的 [N x P] 矩阵\n",
    "\n",
    "A_device = cuda.to_device(A)\n",
    "B_device = cuda.to_device(B)\n",
    "C_device = cuda.device_array((M, P)) # [M x P] 矩阵\n",
    "\n",
    "# 执行配置\n",
    "threads_per_block = (BLOCK_SIZE, BLOCK_SIZE)\n",
    "blocks_per_grid_x = int(math.ceil(A.shape[0] / BLOCK_SIZE))\n",
    "blocks_per_grid_y = int(math.ceil(B.shape[1] / BLOCK_SIZE))\n",
    "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "start = time()\n",
    "matmul[blocks_per_grid, threads_per_block](A_device, B_device, C_device)\n",
    "cuda.synchronize()\n",
    "print(\"matmul time :\" + str(time() - start))\n",
    "\n",
    "start = time()\n",
    "matmul_shared_memory[blocks_per_grid, threads_per_block](A_device, B_device, C_device)\n",
    "cuda.synchronize()\n",
    "print(\"matmul with shared memory time :\" + str(time() - start))\n",
    "C = C_device.copy_to_host()\n",
    "\n",
    "# 验证正确性\n",
    "if np.allclose(C, np.dot(A, B)):\n",
    "    print(\"matmul with shared memory, result correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435c8aa-5517-4e0f-967a-7bf6a403f53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c784b-a609-4906-91b3-9c21e078a107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9b44c-55e9-4867-9e3a-affdd9d9763c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a127f-6388-436c-a2c8-e2e19de5035c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3-11_programing",
   "language": "python",
   "name": "py-3-11_programing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
