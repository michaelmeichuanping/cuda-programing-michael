{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8778d4c-0244-4457-8967-fd933974c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "import math\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9023307b-5b7e-4976-93fc-b97225a07442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for vector sum, run it over GPU\n",
    "@cuda.jit\n",
    "def gpu_add(a, b, result, n):\n",
    "    # a, b为输入向量，result为输出向量\n",
    "    # 向量维度为n\n",
    "    # 得到当前thread的编号\n",
    "    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    if idx < n:\n",
    "        result[idx] = a[idx] + b[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe71bdb-664c-43f6-80cb-ccfa7df8fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create 2 x vectors in 20M-dimension. covert them into int32\n",
    "#  Pass them to the function as the parameters\n",
    "n = 20000000\n",
    "# 之前是生成一个值比较整齐的向量，而现在改成了一个值更为随机的向量\n",
    "x = np.random.uniform(10,20,n)\n",
    "y = np.random.uniform(10,20,n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902ade94-ed10-4eaf-b2ea-73b658e62ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建n维全0向量, 作为vector sum的初始值\n",
    "# gpu_result = np.zeros(n)\n",
    "# cpu_result = np.zeros(n)\n",
    "\n",
    "# manually copy data from the main memory to the GPU memory\n",
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "# 在显卡设备上初始化一块GPU memory, for storing GPU计算结果, 以避免结果被回送到CPU\n",
    "gpu_result = cuda.device_array(n)\n",
    "# 在显卡设备上再初始化一块GPU memory, for storing GPU计算结果(with multi-stream pipeline)\n",
    "z_streams_device = cuda.device_array(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34cf7db8-a56c-488a-a5d5-6a1b7ed7b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate CUDA execution configuration [gridDim, blockDim]\n",
    "threads_per_block = 1024\n",
    "blocks_per_grid = math.ceil(n / threads_per_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8e424e-4b7d-4753-93a0-2e802fd38bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu vector add time 0.23417901992797852\n"
     ]
    }
   ],
   "source": [
    "# get time-stamp when start\n",
    "start = time()\n",
    "\n",
    "# use GPU to do do vector sum, with execution configuration [19532, 1024]\n",
    "# gpu_add[blocks_per_grid, threads_per_block](x, y, gpu_result, n)\n",
    "# use data which has been manually copied into the GPU memory, instead of data in CPU memory\n",
    "gpu_add[blocks_per_grid, threads_per_block](x_device, y_device, gpu_result, n)\n",
    "    \n",
    "# Device To Host\n",
    "default_stream_result = gpu_result.copy_to_host()\n",
    "\n",
    "cuda.synchronize()\n",
    "\n",
    "# print time consumed by GPU\n",
    "print(\"gpu vector add time \" + str(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83e4059-905e-4eb5-a1d7-d696d6dbca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- gpu_result= <numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f99aa0dff90>\n",
      "- default_stream_result= [31.53105299 37.98745602 33.26618915 ... 30.62157485 30.98065319\n",
      " 31.1716254 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"- gpu_result=\", gpu_result)\n",
    "print(\"- default_stream_result=\", default_stream_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24af57e-d474-450c-8371-de996cfaabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are calcualtion time required when multi-stream is enabled\n",
    "\n",
    "# resset timer for test of multi-stream-enabled configuration\n",
    "start = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc460f2-23a5-4836-9c1e-8367aa148ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 5-stream\n",
    "number_of_streams = 5\n",
    "# 每个流处理的数据量为原来的 1/5, //: 做除法并只保留整数部分\n",
    "segment_size = n // number_of_streams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda6c29e-883a-4a40-9bc0-f4fb26e45178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5个cuda stream\n",
    "stream_list = list()\n",
    "for i in range (0, number_of_streams):\n",
    "    stream = cuda.stream()\n",
    "    stream_list.append(stream)\n",
    "\n",
    "threads_per_block = 1024\n",
    "# 每个stream的处理的数据变为原来的1/5\n",
    "blocks_per_grid = math.ceil(segment_size / threads_per_block)\n",
    "streams_result = np.empty(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33acb63b-448f-43b9-951a-03050a7b621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu streams vector add time 31.999213695526123\n",
      "result correct\n"
     ]
    }
   ],
   "source": [
    "# 启动多个stream\n",
    "for i in range(0, number_of_streams):\n",
    "    # 传入不同的参数，让函数在不同的流执行\n",
    "\n",
    "    # Host To Device\n",
    "    # manually copy data from the main memory to the GPU memory\n",
    "    x_i_device = cuda.to_device(x[i * segment_size : (i + 1) * segment_size], stream=stream_list[i])\n",
    "    y_i_device = cuda.to_device(y[i * segment_size : (i + 1) * segment_size], stream=stream_list[i])\n",
    "\n",
    "    # Kernel\n",
    "    gpu_add[blocks_per_grid, threads_per_block, stream_list[i]](\n",
    "        x_i_device,\n",
    "        y_i_device,\n",
    "        z_streams_device[i * segment_size : (i + 1) * segment_size],\n",
    "        segment_size)\n",
    "\n",
    "    # Device To Host\n",
    "    streams_result[i * segment_size : (i + 1) * segment_size] = z_streams_device[i * segment_size : (i + 1) * segment_size].copy_to_host(stream=stream_list[i])\n",
    "\n",
    "cuda.synchronize()\n",
    "print(\"gpu streams vector add time \" + str(time() - start))\n",
    "\n",
    "if (np.array_equal(default_stream_result, streams_result)):\n",
    "    print(\"result correct\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e365358-820e-4843-a9eb-62a8fcf054ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result correct\n"
     ]
    }
   ],
   "source": [
    "if (np.array_equal(default_stream_result, streams_result)):\n",
    "    print(\"result correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1f211-b539-4dfa-a8c4-c2fe11b79df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3-11_programing",
   "language": "python",
   "name": "py-3-11_programing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
